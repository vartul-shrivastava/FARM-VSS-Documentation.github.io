<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>W-FARM and FARM &#8212; FARM-VSS-Documentation  documentation</title>
    <link rel="stylesheet" type="text/css" href="static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="static/basic.css" />
    <link rel="stylesheet" type="text/css" href="static/alabaster.css" />
    <script src="static/jquery.js"></script>
    <script src="static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="static/documentation_options.js"></script>
    <script src="static/doctools.js"></script>
    <script src="static/sphinx_highlight.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Partitioning and FARM Rule Exploration" href="partitioning_farm_exploration.html" />
   
  <link rel="stylesheet" href="static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="w-farm-and-farm">
<h1><a class="toc-backref" href="#id1" role="doc-backlink">W-FARM and FARM</a><a class="headerlink" href="#w-farm-and-farm" title="Link to this heading"></a></h1>
<p>FARM-VSS utilizes advanced algorithms for Fuzzy Association Rule Mining (FARM) and its weighted variant (W-FARM). This section delves into the theoretical foundations, formulas, and methodologies employed in FARM-VSS for generating and refining association rules.</p>
<nav class="contents" id="table-of-contents">
<p class="topic-title">Table of Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#w-farm-and-farm" id="id1">W-FARM and FARM</a></p>
<ul>
<li><p><a class="reference internal" href="#introduction-to-farm" id="id2">Introduction to FARM</a></p></li>
<li><p><a class="reference internal" href="#farm-formula" id="id3">FARM Formula</a></p></li>
<li><p><a class="reference internal" href="#conclusion" id="id4">Conclusion</a></p></li>
</ul>
</li>
</ul>
</nav>
<section id="introduction-to-farm">
<h2><a class="toc-backref" href="#id2" role="doc-backlink">Introduction to FARM</a><a class="headerlink" href="#introduction-to-farm" title="Link to this heading"></a></h2>
<p>Fuzzy Association Rule Mining (FARM) extends traditional association rule mining by incorporating fuzzy logic. This approach allows for handling the inherent uncertainty and vagueness in data, enabling the discovery of more nuanced and meaningful association rules.</p>
<section id="what-is-farm">
<h3>What is FARM?<a class="headerlink" href="#what-is-farm" title="Link to this heading"></a></h3>
<p>FARM leverages fuzzy sets to define the relationships between different variables in a dataset. Unlike classical association rule mining, which operates on crisp boundaries, FARM allows for degrees of membership, providing a more flexible and realistic modeling of real-world data.</p>
</section>
<section id="what-is-w-farm">
<h3>What is W-FARM?<a class="headerlink" href="#what-is-w-farm" title="Link to this heading"></a></h3>
<p>Weighted Fuzzy Association Rule Mining (W-FARM) is an extension of FARM that incorporates weights to indicate the significance of different partitions. By assigning weights, users can emphasize certain aspects of the data, enhancing the relevance of the generated rules.</p>
</section>
</section>
<section id="farm-formula">
<h2><a class="toc-backref" href="#id3" role="doc-backlink">FARM Formula</a><a class="headerlink" href="#farm-formula" title="Link to this heading"></a></h2>
<p>The core of FARM lies in its ability to generate association rules based on fuzzy partitions and evaluate their significance and certainty.</p>
<section id="generating-association-rules">
<h3>Generating Association Rules<a class="headerlink" href="#generating-association-rules" title="Link to this heading"></a></h3>
<p>An association rule in FARM is typically represented as:</p>
<div class="math notranslate nohighlight">
\[X \Rightarrow Y\]</div>
<p>Where:
- <strong>X</strong> and <strong>Y</strong> are sets of fuzzy attributes.
- The rule implies that when <strong>X</strong> occurs, <strong>Y</strong> is likely to occur.</p>
</section>
<section id="significance-and-certainty">
<h3>Significance and Certainty<a class="headerlink" href="#significance-and-certainty" title="Link to this heading"></a></h3>
<p>Two critical metrics evaluate the quality of an association rule:</p>
<ol class="arabic">
<li><p><strong>Significance (Support):</strong></p>
<p>Significance measures how frequently the rule appears in the dataset. It indicates the strength of the association between the antecedent and consequent.</p>
<div class="math notranslate nohighlight">
\[\text{Support}(X \Rightarrow Y) = \frac{\text{Number of transactions containing } X \text{ and } Y}{\text{Total number of transactions}}\]</div>
</li>
<li><p><strong>Certainty (Confidence):</strong></p>
<p>Certainty assesses the reliability of the rule. It reflects the likelihood of the consequent <strong>Y</strong> given the antecedent <strong>X</strong>.</p>
<div class="math notranslate nohighlight">
\[\text{Confidence}(X \Rightarrow Y) = \frac{\text{Support}(X \Rightarrow Y)}{\text{Support}(X)}\]</div>
</li>
</ol>
</section>
<section id="itemset-pruning">
<h3>Itemset Pruning<a class="headerlink" href="#itemset-pruning" title="Link to this heading"></a></h3>
<p>In FARM, itemsets are combinations of fuzzy attributes that meet or exceed predefined significance and certainty thresholds. Pruning involves eliminating itemsets that do not meet these criteria to refine the rule generation process.</p>
</section>
<section id="how-itemsets-are-pruned">
<h3>How Itemsets are Pruned<a class="headerlink" href="#how-itemsets-are-pruned" title="Link to this heading"></a></h3>
<ol class="arabic simple">
<li><p><strong>Initial Generation:</strong></p>
<ul class="simple">
<li><p>Begin with individual fuzzy attributes (1-itemsets).</p></li>
<li><p>Calculate their significance and certainty.</p></li>
</ul>
</li>
<li><p><strong>Pruning Based on Thresholds:</strong></p>
<ul class="simple">
<li><p>Remove itemsets that do not meet the minimum support (<cite>min_support</cite>) and minimum confidence (<cite>min_certainty</cite>) thresholds.</p></li>
</ul>
</li>
<li><p><strong>Iterative Combination:</strong></p>
<ul class="simple">
<li><p>Combine remaining itemsets to form larger combinations (e.g., 2-itemsets, 3-itemsets).</p></li>
<li><p>Repeat the pruning process at each level.</p></li>
</ul>
</li>
<li><p><strong>Termination:</strong></p>
<ul class="simple">
<li><p>The process continues until no further combinations meet the threshold criteria.</p></li>
</ul>
</li>
</ol>
</section>
<section id="significance-and-certainty-in-rule-evaluation">
<h3>Significance and Certainty in Rule Evaluation<a class="headerlink" href="#significance-and-certainty-in-rule-evaluation" title="Link to this heading"></a></h3>
<ul>
<li><p><strong>Significance (Support):</strong></p>
<p>Indicates the overall prevalence of the rule in the dataset. High support suggests that the rule is applicable to a substantial portion of the data.</p>
</li>
<li><p><strong>Certainty (Confidence):</strong></p>
<p>Reflects the reliability of the rule. High confidence implies that the occurrence of the antecedent <strong>X</strong> strongly predicts the occurrence of the consequent <strong>Y</strong>.</p>
</li>
</ul>
</section>
<section id="farm-algorithm-steps">
<h3>FARM Algorithm Steps<a class="headerlink" href="#farm-algorithm-steps" title="Link to this heading"></a></h3>
<ol class="arabic simple">
<li><p><strong>Data Preprocessing:</strong></p>
<ul class="simple">
<li><p>Clean and normalize the dataset.</p></li>
<li><p>Identify numerical and categorical attributes.</p></li>
</ul>
</li>
<li><p><strong>Fuzzy Partitioning:</strong></p>
<ul class="simple">
<li><p>Partition numerical attributes into fuzzy sets (e.g., low, medium, high).</p></li>
<li><p>Assign membership degrees to each data point based on the fuzzy sets.</p></li>
</ul>
</li>
<li><p><strong>Rule Generation:</strong></p>
<ul class="simple">
<li><p>Apply the Apriori algorithm to generate association rules from the fuzzy partitions.</p></li>
<li><p>Calculate support and confidence for each rule.</p></li>
</ul>
</li>
<li><p><strong>Pruning:</strong></p>
<ul class="simple">
<li><p>Eliminate rules that do not meet the minimum support and confidence thresholds.</p></li>
<li><p>Refine the rule set iteratively.</p></li>
</ul>
</li>
<li><p><strong>Rule Evaluation:</strong></p>
<ul class="simple">
<li><p>Analyze the pruned rules to identify meaningful associations.</p></li>
<li><p>Utilize AI models for summarization and insight generation.</p></li>
</ul>
</li>
</ol>
</section>
<section id="example">
<h3>Example<a class="headerlink" href="#example" title="Link to this heading"></a></h3>
<p>Consider a dataset of customer purchases with numerical attributes like <cite>AmountSpent</cite> and <cite>Frequency</cite>.</p>
<ol class="arabic simple">
<li><p><strong>Fuzzy Partitioning:</strong></p>
<ul class="simple">
<li><p><cite>AmountSpent</cite> is partitioned into <cite>Low</cite>, <cite>Medium</cite>, <cite>High</cite>.</p></li>
<li><p><cite>Frequency</cite> is partitioned into <cite>Rare</cite>, <cite>Occasional</cite>, <cite>Frequent</cite>.</p></li>
</ul>
</li>
<li><p><strong>Rule Generation:</strong></p>
<ul class="simple">
<li><p>Example Rule: If <cite>AmountSpent</cite> is <cite>High</cite> and <cite>Frequency</cite> is <cite>Frequent</cite>, then <cite>ProductCategory</cite> is <cite>Electronics</cite>.</p></li>
</ul>
</li>
<li><p><strong>Evaluation:</strong></p>
<ul class="simple">
<li><p><strong>Support:</strong> 0.25 (25% of transactions meet this rule)</p></li>
<li><p><strong>Confidence:</strong> 0.80 (80% of transactions with <cite>High</cite> spending and <cite>Frequent</cite> visits are in <cite>Electronics</cite>)</p></li>
</ul>
</li>
</ol>
<p>Since both support and confidence exceed typical thresholds (e.g., 0.15 and 0.60), the rule is retained.</p>
</section>
</section>
<section id="conclusion">
<h2><a class="toc-backref" href="#id4" role="doc-backlink">Conclusion</a><a class="headerlink" href="#conclusion" title="Link to this heading"></a></h2>
<p>Understanding the theoretical underpinnings of FARM and W-FARM is essential for effectively utilizing FARM-VSS. By leveraging fuzzy logic and incorporating significance and certainty metrics, FARM-VSS enables the discovery of meaningful and reliable association rules, facilitating data-driven decision-making.</p>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
          <a href="index.html"><img style="margin-bottom: 50px;" src="./b-logo.svg" alt=""></a>





<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="ollama_ai_models.html">Ollama AI Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="partitioning_farm_exploration.html">Partitioning and FARM Rule Exploration</a></li>
<li class="toctree-l1"><a class="reference internal" href="partitioning_farm_exploration.html#brute-force-grid-farm-rule-exploration">Brute-Force Grid FARM Rule Exploration</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">W-FARM and FARM</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#introduction-to-farm">Introduction to FARM</a></li>
<li class="toctree-l2"><a class="reference internal" href="#farm-formula">FARM Formula</a></li>
<li class="toctree-l2"><a class="reference internal" href="#conclusion">Conclusion</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="partitioning_farm_exploration.html" title="previous chapter">Partitioning and FARM Rule Exploration</a></li>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2024, Vartul Shrivastava, Prof. Shekhar Shukla.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.1.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
      |
      <a href="_sources/wfarm_farm.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>